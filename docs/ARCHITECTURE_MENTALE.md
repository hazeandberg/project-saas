# ðŸ—ºï¸ Carte Mentale Architecture - SaaS PME Data Ã— IA

## 1ï¸âƒ£ CARTE MENTALE GLOBALE

```
PROJECT-SAAS
â”‚
â”œâ”€ ðŸ“ DATA BRUTES (data/raw/)
â”‚  â”œâ”€ clients.csv
â”‚  â”œâ”€ subscriptions.csv
â”‚  â””â”€ usage.csv
â”‚
â”œâ”€ ðŸ”„ PIPELINE TRANSFORMATION (src/pipeline/)
â”‚  â””â”€ OOP Processing â†’ report_oop.csv + kpi_by_client.csv
â”‚
â”œâ”€ ðŸ¤– ML WORKFLOW (src/ml/)
â”‚  â”œâ”€ Build ML-ready dataset
â”‚  â”œâ”€ Train churn_model_v1
â”‚  â””â”€ Generate metrics + artifacts
â”‚
â”œâ”€ ðŸ“Š DASHBOARDS (src/dashboards/)
â”‚  â”œâ”€ app_v5.py (gÃ©nÃ©rale)
â”‚  â””â”€ app_v6_churn.py (churn-focused)
â”‚
â”œâ”€ ðŸ”Œ API (src/api/)
â”‚  â””â”€ FastAPI /predict endpoint
â”‚
â”œâ”€ ðŸ§  RAG SYSTEM (src/rag/)
â”‚  â”œâ”€ Build index (ChromaDB)
â”‚  â””â”€ Query corpus
â”‚
â”œâ”€ ðŸ¤– AGENT (src/agent/)
â”‚  â”œâ”€ orchestrator.py (dÃ©cisions)
â”‚  â”œâ”€ RAG tool
â”‚  â”œâ”€ Stats tool
â”‚  â”œâ”€ Churn prediction tool
â”‚  â””â”€ Revenue tool
â”‚
â””â”€ ðŸ³ DOCKER DEPLOYMENT
   â””â”€ docker-compose.yml
```

---

## 2ï¸âƒ£ FLUX DE LA DATA

```
Ã‰TAPE 1: RAW DATA READING
  data/raw/*.csv â†’ pandas DataFrames

Ã‰TAPE 2: CLEANING & PARSING (parse_clean.py)
  â”œâ”€ Fix dates
  â”œâ”€ Handle nulls
  â””â”€ Type conversion

Ã‰TAPE 3: OOP PROCESSING (pipeline_oop.py)
  â”œâ”€ Group by client
  â”œâ”€ Aggregate payments/usage
  â””â”€ Calculate KPIs
  
  ðŸ“¤ OUTPUT: report_oop.csv
           kpi_by_client.csv

Ã‰TAPE 4: ML-READY BUILDING (build_ml_churn_ready_v1.py)
  â”œâ”€ Merge report + KPIs
  â”œâ”€ Create features (paid_count, days_since_paid, etc.)
  â”œâ”€ Label target (churn_7_30j)
  â””â”€ Train/test split
  
  ðŸ“¤ OUTPUT: df_ml_ready.csv

Ã‰TAPE 5: MODEL TRAINING (train_churn_model_v1.py)
  â”œâ”€ Load df_ml_ready.csv
  â”œâ”€ Train Logistic Regression
  â”œâ”€ Evaluate metrics
  â””â”€ Save joblib artifact
  
  ðŸ“¤ OUTPUT: churn_model_v1.joblib
           churn_metrics_v1.json

Ã‰TAPE 6: SERVING
  â”œâ”€ API loads model â†’ /predict endpoint
  â”œâ”€ Dashboards load report_oop + metrics
  â””â”€ Agent uses all for decision-making
```

---

## 3ï¸âƒ£ INTERACTIONS FICHIERS/SCRIPTS

```
MAIN ENTRY POINTS:

1ï¸âƒ£ python -m src.ml.train_churn_model_v1
   â”‚
   â”œâ”€ reads: data/ml_ready/df_ml_ready.csv
   â”œâ”€ imports: src.pipeline.* (processing logic)
   â”œâ”€ trains: Logistic Regression
   â”‚
   â””â”€ outputs:
      â”œâ”€ src/ml/models/churn_model_v1.joblib
      â””â”€ data/ml_ready/churn_metrics_v1.json

2ï¸âƒ£ python -m uvicorn src.api.main:app
   â”‚
   â”œâ”€ imports: src.ml.models/churn_model_v1.joblib
   â”œâ”€ exposes: POST /predict
   â”‚
   â””â”€ request format:
      {paid_count_before_T, paid_sum_before_T, 
       days_since_last_paid, plan, ville}

3ï¸âƒ£ streamlit run src/dashboards/app_v6_churn.py
   â”‚
   â”œâ”€ reads: data/processed/report_oop.csv
   â”œâ”€ reads: data/ml_ready/churn_metrics_v1.json
   â”œâ”€ loads: src/ml/models/churn_model_v1.joblib
   â”‚
   â””â”€ displays: KPIs + churn predictions

4ï¸âƒ£ python -m src.agent.orchestrator
   â”‚
   â”œâ”€ imports: src.agent.tools_*.py
   â”œâ”€ reads: data/processed/report_oop.csv (for stats)
   â”œâ”€ queries: ChromaDB (docs_corpus â†’ RAG)
   â”œâ”€ calls: http://api:8000/predict (churn predictions)
   â”‚
   â””â”€ returns: AgentResponse(question, answer_md, debug)
```

---

## 4ï¸âƒ£ LOGIQUE RAG + AGENT

```
USER QUESTION
      â”‚
      â–¼
AGENT.ask(question, client_id)
      â”‚
      â”œâ”€ ðŸ” TOOL 1: RAG_QUERY
      â”‚  â””â”€ Embed question â†’ search ChromaDB (docs_corpus)
      â”‚     â†’ return top-4 chunks (rÃ¨gles/playbooks)
      â”‚
      â”œâ”€ ðŸ‘¤ TOOL 2: STATS_CLIENT (si client_id fourni)
      â”‚  â””â”€ Read report_oop.csv
      â”‚     â†’ filter by client_id
      â”‚     â†’ return {nb_paiements, ca_total, plan, ville, etc.}
      â”‚
      â”œâ”€ ðŸ“ˆ TOOL 3: REVENUE_EVENTS (si client_id fourni)
      â”‚  â””â”€ Lookup client events
      â”‚     â†’ return revenue summary
      â”‚
      â”œâ”€ âš ï¸ TOOL 4: PREDICT_CHURN (si client_id fourni)
      â”‚  â”œâ”€ Get stats via tool_stats
      â”‚  â”œâ”€ POST to /predict API
      â”‚  â””â”€ return {churn_probability, churn_risk}
      â”‚
      â””â”€ ðŸŽ¯ FORMAT ANSWER (non-tech format)
         â””â”€ return AgentResponse:
            â€¢ RÃ©sumÃ©
            â€¢ Pourquoi (3 bullets)
            â€¢ Action recommandÃ©e
            â€¢ Action prÃ©parÃ©e
            â€¢ Confiance
```

---

## 5ï¸âƒ£ POINT DE VUE UTILISATEUR

```
SCENARIO 1: Je veux entraÃ®ner un modÃ¨le de churn
  $ python -m src.ml.train_churn_model_v1
  
  âœ… LE CODE FAIT:
     1. Lit les donnÃ©es brutes
     2. CrÃ©e features ML
     3. EntraÃ®ne un modÃ¨le
     4. Sauvegarde le modÃ¨le (artifact)
     5. Ã‰value performance (metrics)
  
  ðŸ“¦ FICHIERS CRÃ‰Ã‰S:
     - src/ml/models/churn_model_v1.joblib
     - data/ml_ready/churn_metrics_v1.json


SCENARIO 2: Je veux voir les prÃ©dictions en temps rÃ©el
  $ python -m uvicorn src.api.main:app --reload
  
  âœ… LE CODE FAIT:
     1. DÃ©marre un serveur web
     2. Charge le modÃ¨le en mÃ©moire
     3. Accepte requÃªtes JSON
     4. Retourne prÃ©dictions
  
  ðŸ”— URL:
     POST http://localhost:8000/predict
     GET  http://localhost:8000/docs (interactive docs)


SCENARIO 3: Je veux visualiser les mÃ©triques
  $ streamlit run src/dashboards/app_v6_churn.py
  
  âœ… LE CODE FAIT:
     1. Lit le rapport de clients
     2. Lit les mÃ©triques du modÃ¨le
     3. Affiche graphiques interactifs
  
  ðŸ“Š AFFICHAGE:
     - KPIs par client
     - Distribution churn
     - Comparaisons


SCENARIO 4: Je veux poser une question commerciale
  >>> agent = CopilotAgent()
  >>> agent.ask("Comment Ã©viter la fuite client ?")
  
  âœ… LE CODE FAIT:
     1. Cherche dans la base de connaissances (RAG)
     2. Retourne rÃ¨gles + playbooks
     3. Formatte rÃ©ponse pour non-tech
  
  ðŸ’¡ RÃ‰SULTAT:
     RÃ©ponse structurÃ©e avec:
     - Explication simple
     - Actions concrÃ¨tes
     - Confiance (faible/moyen/fort)
```

---

## âš¡ SYNTHÃˆSE POINTS CLÃ‰S

| Aspect | Description |
|--------|-------------|
| **DonnÃ©es** | CSV â†’ Pandas â†’ AgrÃ©gation OOP â†’ Report structurÃ© |
| **ML** | Features + Label â†’ Logistic Regression â†’ Model joblib |
| **Serving** | FastAPI charge model â†’ /predict endpoint |
| **Dashboards** | Streamlit lit report_oop + metrics â†’ affiche KPIs |
| **Intelligence** | Agent utilise RAG (docs) + Stats (report) + PrÃ©dictions (API) |
| **DÃ©ploiement** | Docker Compose lance tout ensemble |

---

## ðŸ”— RÃ‰FÃ‰RENCES FICHIERS CLÃ‰S

- **Pipeline Data** â†’ `src/pipeline/pipeline_oop.py`
- **ML Training** â†’ `src/ml/train_churn_model_v1.py`
- **API** â†’ `src/api/main.py`
- **Dashboards** â†’ `src/dashboards/app_v6_churn.py`
- **RAG** â†’ `src/rag/rag_query.py` + `src/rag/build_index.py`
- **Agent** â†’ `src/agent/orchestrator.py`
- **Corpus** â†’ `docs_corpus/` (40_response_format.md, 30_playbooks_retention.md, etc.)
